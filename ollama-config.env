# Ollama Configuration for AMCP Integration
# This file contains optimized settings for running Ollama with TinyLlama

# Memory and Performance Settings
OLLAMA_MAX_LOADED_MODELS=1
OLLAMA_NUM_PARALLEL=1
OLLAMA_MAX_QUEUE=4
OLLAMA_KEEP_ALIVE=5m
OLLAMA_LOAD_TIMEOUT=5m

# Network Settings
OLLAMA_HOST=0.0.0.0
OLLAMA_PORT=11434

# Model Settings
OLLAMA_MODELS=/usr/share/ollama/.ollama/models

# Logging
OLLAMA_DEBUG=false

# Resource Limits (adjust based on your system)
OLLAMA_MAX_VRAM=2048
OLLAMA_LLM_LIBRARY=cpu

# Timeout Settings
OLLAMA_REQUEST_TIMEOUT=120
OLLAMA_LOAD_TIMEOUT=300
