#!/bin/bash

# Simple OLLAMA TinyLlama Demo Runner for AMCP v1.5
echo "üöÄ AMCP OLLAMA TinyLlama 1.1B Demo"
echo "=================================="

# Set JAVA_HOME
export JAVA_HOME="/opt/homebrew/Cellar/openjdk@21/21.0.8/libexec/openjdk.jdk/Contents/Home"

# Check OLLAMA service
echo "üîç Checking OLLAMA..."
if ! curl -s http://localhost:11434/api/tags > /dev/null; then
    echo "‚ùå OLLAMA not running. Start with: brew services start ollama"
    exit 1
fi

# Check TinyLlama model
if ! ollama list | grep -q tinyllama; then
    echo "üì• Downloading TinyLlama..."
    ollama pull tinyllama
fi

echo "‚úÖ All prerequisites ready!"
echo ""
echo "üí° TinyLlama 1.1B Info:"
echo "   ‚Ä¢ Size: ~637MB download, ~2-3GB RAM"
echo "   ‚Ä¢ Speed: Very fast due to small parameter count"
echo "   ‚Ä¢ Use case: Basic conversation, lightweight AI"
echo ""
echo "üéØ Demo Commands:"
echo "   ‚Ä¢ Type messages to chat with TinyLlama"
echo "   ‚Ä¢ /help - Show commands"
echo "   ‚Ä¢ /model - Model information"
echo "   ‚Ä¢ /exit - Quit demo"
echo ""

# Build classpath
CLASSPATH="connectors/target/classes:core/target/classes"
if [ -d "lib" ]; then
    CLASSPATH="$CLASSPATH:lib/*"
fi

echo "üöÄ Starting demo..."
echo ""

java -cp "$CLASSPATH" io.amcp.connectors.ollama.OllamaIntegrationDemo